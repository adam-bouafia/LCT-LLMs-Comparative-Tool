"""
Generated LLM Comparison Configuration
Experiment: small_llm_test
Generated by LLM Experiment Runner
"""

from llm_runner.configs.llm_comparison_config import LLMComparisonConfig
from llm_runner.loaders.universal_loader import ModelLoadConfig


class RunnerConfig(LLMComparisonConfig):
    """Configuration for small_llm_test experiment."""
    
    # Experiment configuration
    name = "small_llm_test"
    results_output_path = r"/home/neo/Documents/experiment runner/llm-experiment-runner/experiments"
    
    # Model configuration
    model_ids = ['microsoft/DialoGPT-small', 'distilgpt2']
    
    # Prompt configuration
    prompts = ['Hello, how are you?', 'Explain quantum computing in simple terms.', 'Write a short story about a robot.']
    
    # Algorithm configuration
    comparison_algorithms = ['response_time', 'text_length', 'token_throughput']
    
    # Experiment parameters
    repetitions = 2
    max_memory_gb = 4.0
    
    # Generation parameters
    generation_params = {
        "max_length": 50,
        "temperature": 0.7,
        "do_sample": True,
        "top_p": 0.9
    }
    
    # Model loading configuration
    model_load_config = ModelLoadConfig(
        device="auto",
        torch_dtype="auto",
        trust_remote_code=False,
        low_cpu_mem_usage=True
    )
